{"cells":[{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2021-09-16T14:14:05.905189Z","iopub.status.busy":"2021-09-16T14:14:05.904852Z","iopub.status.idle":"2021-09-16T14:14:07.838794Z","shell.execute_reply":"2021-09-16T14:14:07.838021Z","shell.execute_reply.started":"2021-09-16T14:14:05.905100Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Num GPUs Available:  0\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import os\n","import librosa,librosa.display\n","from tqdm.notebook import tqdm\n","import tensorflow as tf\n","import warnings\n","warnings.filterwarnings('ignore')\n","print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"]},{"cell_type":"markdown","metadata":{},"source":["https://www.kaggle.com/code/rajanmargaye/audio-mnist-with-lstm-auc-93/notebook"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2021-09-16T14:14:07.840542Z","iopub.status.busy":"2021-09-16T14:14:07.840311Z","iopub.status.idle":"2021-09-16T14:14:08.564618Z","shell.execute_reply":"2021-09-16T14:14:08.563779Z","shell.execute_reply.started":"2021-09-16T14:14:07.840502Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(array([-0.04289964, -0.04552099, -0.03932492, ..., -0.00223843,\n","         0.00246574,  0.        ], dtype=float32),\n"," 22050)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["path='../data/0_A_0.wav'\n","raw_data,framerate=librosa.load(path)\n","raw_data,framerate"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2021-09-16T14:14:08.566432Z","iopub.status.busy":"2021-09-16T14:14:08.566164Z","iopub.status.idle":"2021-09-16T14:15:12.066563Z","shell.execute_reply":"2021-09-16T14:15:12.065940Z","shell.execute_reply.started":"2021-09-16T14:14:08.566398Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"58aa2b4c15be4b478258fbc766982e9b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["data=pd.DataFrame(columns=['raw_data','duration','digit',\"person\",\"number_index\"])\n","dir_path='../data/'\n","for i in tqdm(os.listdir(dir_path)):\n","        raw_data,frame_rate=librosa.load(dir_path+i)\n","        duration=librosa.get_duration(raw_data,frame_rate)\n","        data.loc[len(data.index)]=[raw_data,duration,i.split('_')[0],i.split(\"_\")[1],i.split(\"_\")[2].split(\".\")[0]]"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2021-09-16T14:15:12.068841Z","iopub.status.busy":"2021-09-16T14:15:12.068578Z","iopub.status.idle":"2021-09-16T14:15:12.093774Z","shell.execute_reply":"2021-09-16T14:15:12.092934Z","shell.execute_reply.started":"2021-09-16T14:15:12.068809Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>raw_data</th>\n","      <th>duration</th>\n","      <th>digit</th>\n","      <th>person</th>\n","      <th>number_index</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[-0.042899642, -0.045520995, -0.039324917, -0....</td>\n","      <td>0.298005</td>\n","      <td>0</td>\n","      <td>A</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[0.0010019833, 0.00088148087, 0.0006781536, 0....</td>\n","      <td>0.590884</td>\n","      <td>0</td>\n","      <td>A</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[-0.0077365004, -0.014448198, -0.016177949, -0...</td>\n","      <td>0.744762</td>\n","      <td>0</td>\n","      <td>A</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[0.003040686, 0.0036373322, 0.003993512, 0.004...</td>\n","      <td>0.457642</td>\n","      <td>0</td>\n","      <td>A</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[0.0020078255, 0.002592097, 0.00282455, 0.0028...</td>\n","      <td>0.506259</td>\n","      <td>0</td>\n","      <td>A</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2995</th>\n","      <td>[-0.0001598679, -0.0003172595, -0.00037161465,...</td>\n","      <td>0.359637</td>\n","      <td>9</td>\n","      <td>F</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2996</th>\n","      <td>[-0.00019665736, -7.2244766e-05, 0.00013556477...</td>\n","      <td>0.347256</td>\n","      <td>9</td>\n","      <td>F</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>2997</th>\n","      <td>[0.00022448921, 0.00018810731, 0.00012995154, ...</td>\n","      <td>0.351882</td>\n","      <td>9</td>\n","      <td>F</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>2998</th>\n","      <td>[0.00031612845, 0.0002592627, 0.0001870415, 0....</td>\n","      <td>0.395510</td>\n","      <td>9</td>\n","      <td>F</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>2999</th>\n","      <td>[-9.788064e-05, -0.00019046968, -0.0002379634,...</td>\n","      <td>0.438413</td>\n","      <td>9</td>\n","      <td>F</td>\n","      <td>9</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3000 rows Ã— 5 columns</p>\n","</div>"],"text/plain":["                                               raw_data  duration digit  \\\n","0     [-0.042899642, -0.045520995, -0.039324917, -0....  0.298005     0   \n","1     [0.0010019833, 0.00088148087, 0.0006781536, 0....  0.590884     0   \n","2     [-0.0077365004, -0.014448198, -0.016177949, -0...  0.744762     0   \n","3     [0.003040686, 0.0036373322, 0.003993512, 0.004...  0.457642     0   \n","4     [0.0020078255, 0.002592097, 0.00282455, 0.0028...  0.506259     0   \n","...                                                 ...       ...   ...   \n","2995  [-0.0001598679, -0.0003172595, -0.00037161465,...  0.359637     9   \n","2996  [-0.00019665736, -7.2244766e-05, 0.00013556477...  0.347256     9   \n","2997  [0.00022448921, 0.00018810731, 0.00012995154, ...  0.351882     9   \n","2998  [0.00031612845, 0.0002592627, 0.0001870415, 0....  0.395510     9   \n","2999  [-9.788064e-05, -0.00019046968, -0.0002379634,...  0.438413     9   \n","\n","     person number_index  \n","0         A            0  \n","1         A            1  \n","2         A           10  \n","3         A           11  \n","4         A           12  \n","...     ...          ...  \n","2995      F            5  \n","2996      F            6  \n","2997      F            7  \n","2998      F            8  \n","2999      F            9  \n","\n","[3000 rows x 5 columns]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["data"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2021-09-16T14:15:12.095619Z","iopub.status.busy":"2021-09-16T14:15:12.095334Z","iopub.status.idle":"2021-09-16T14:15:12.111636Z","shell.execute_reply":"2021-09-16T14:15:12.110924Z","shell.execute_reply.started":"2021-09-16T14:15:12.095585Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(data[['raw_data','duration']],data['digit'], test_size=0.3, random_state=45,stratify=data['digit'])"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2021-09-16T14:15:12.113202Z","iopub.status.busy":"2021-09-16T14:15:12.112955Z","iopub.status.idle":"2021-09-16T14:15:12.140899Z","shell.execute_reply":"2021-09-16T14:15:12.140265Z","shell.execute_reply.started":"2021-09-16T14:15:12.113172Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0  th percentile is  3167.0\n","10  th percentile is  6092.0\n","20  th percentile is  7198.8\n","30  th percentile is  7933.0\n","40  th percentile is  8650.0\n","50  th percentile is  9270.0\n","60  th percentile is  9971.199999999999\n","70  th percentile is  10799.0\n","80  th percentile is  11761.6\n","90  th percentile is  13334.400000000005\n","100  th percentile is  50335.0\n"]}],"source":["for i in range(0,101,10):\n","    print(i,' th percentile is ',np.percentile([len(i) for i in X_train['raw_data']],i))"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2021-09-16T14:15:12.143751Z","iopub.status.busy":"2021-09-16T14:15:12.143558Z","iopub.status.idle":"2021-09-16T14:15:12.168691Z","shell.execute_reply":"2021-09-16T14:15:12.168081Z","shell.execute_reply.started":"2021-09-16T14:15:12.143729Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["90  th percentile is  13334.400000000005\n","91  th percentile is  13570.720000000001\n","92  th percentile is  13801.24\n","93  th percentile is  13995.190000000002\n","94  th percentile is  14217.84\n","95  th percentile is  14664.25\n","96  th percentile is  15274.519999999997\n","97  th percentile is  16422.18\n","98  th percentile is  18049.059999999998\n","99  th percentile is  20768.21999999983\n","100  th percentile is  50335.0\n"]}],"source":["for i in range(90,101,1):\n","    print(i,' th percentile is ',np.percentile([len(i) for i in X_train['raw_data']],i))"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2021-09-16T14:15:12.171107Z","iopub.status.busy":"2021-09-16T14:15:12.170865Z","iopub.status.idle":"2021-09-16T14:15:12.175532Z","shell.execute_reply":"2021-09-16T14:15:12.174748Z","shell.execute_reply.started":"2021-09-16T14:15:12.171078Z"},"trusted":true},"outputs":[],"source":["max_length=50335"]},{"cell_type":"markdown","metadata":{},"source":["### We are padding the sequence as we going to use LSTM"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2021-09-16T14:15:12.177114Z","iopub.status.busy":"2021-09-16T14:15:12.176711Z","iopub.status.idle":"2021-09-16T14:15:16.020580Z","shell.execute_reply":"2021-09-16T14:15:16.019795Z","shell.execute_reply.started":"2021-09-16T14:15:12.177078Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","X_train_pad=tf.keras.preprocessing.sequence.pad_sequences(X_train['raw_data'],maxlen=max_length, dtype='float32')\n","X_test_pad=tf.keras.preprocessing.sequence.pad_sequences(X_test['raw_data'],maxlen=max_length, dtype='float32')\n","X_train_mask=np.where(X_train_pad>0.0,True,False)\n","X_test_mask=np.where(X_test_pad>0.0,True,False)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2021-09-16T14:15:16.023808Z","iopub.status.busy":"2021-09-16T14:15:16.023533Z","iopub.status.idle":"2021-09-16T14:15:16.028834Z","shell.execute_reply":"2021-09-16T14:15:16.027102Z","shell.execute_reply.started":"2021-09-16T14:15:16.023775Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.layers import Input, LSTM, Dense\n","from tensorflow.keras.models import Model\n","from sklearn.metrics import f1_score"]},{"cell_type":"markdown","metadata":{},"source":["### Fourier Tranformation is computed on overlapping windowed segments of the signal, and we get what is called the spectrogram\n","### Hence we are converting our raw_data ie time series to spectogram\n","### Mel spectrogram is a spectrogram where the frequencies are converted to the mel scale"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2021-09-16T14:15:16.030451Z","iopub.status.busy":"2021-09-16T14:15:16.030195Z","iopub.status.idle":"2021-09-16T14:15:16.037843Z","shell.execute_reply":"2021-09-16T14:15:16.037117Z","shell.execute_reply.started":"2021-09-16T14:15:16.030417Z"},"trusted":true},"outputs":[],"source":["def convert_to_spectrogram(raw_data):\n","    '''converting to spectrogram'''\n","    spect = librosa.feature.melspectrogram(y=raw_data, n_mels=64) # n_mels as output shape\n","    mel_spect = librosa.power_to_db(S=spect, ref=np.max)\n","    return mel_spect"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2021-09-16T14:15:16.039488Z","iopub.status.busy":"2021-09-16T14:15:16.039186Z","iopub.status.idle":"2021-09-16T14:16:17.539959Z","shell.execute_reply":"2021-09-16T14:16:17.539076Z","shell.execute_reply.started":"2021-09-16T14:15:16.039445Z"},"trusted":true},"outputs":[],"source":["X_train_spectrogram=np.array([convert_to_spectrogram(np.array([float(i) for i in X_train_pad[k] ])) for k in range(len(X_train_pad)) ])\n","X_test_spectrogram=np.array([convert_to_spectrogram(np.array([float(i) for i in X_test_pad[k] ])) for k in range(len(X_test_pad)) ])"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2021-09-16T14:16:17.541855Z","iopub.status.busy":"2021-09-16T14:16:17.541394Z","iopub.status.idle":"2021-09-16T14:16:17.547762Z","shell.execute_reply":"2021-09-16T14:16:17.547048Z","shell.execute_reply.started":"2021-09-16T14:16:17.541820Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(2100, 64, 99)"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["X_train_spectrogram.shape"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2021-09-16T14:16:17.549721Z","iopub.status.busy":"2021-09-16T14:16:17.549209Z","iopub.status.idle":"2021-09-16T14:16:19.827184Z","shell.execute_reply":"2021-09-16T14:16:19.826441Z","shell.execute_reply.started":"2021-09-16T14:16:17.549682Z"},"trusted":true},"outputs":[],"source":["input_layer=Input(shape=(64,99), dtype=np.float32,name='input_layer')\n","lstm=LSTM(500,name='lstm_layer',return_sequences=True)(input_layer)\n","d1=Dense(120,activation='relu',name='dense1')(tf.math.reduce_mean(lstm, 2))\n","d2=Dense(60,activation='relu',name='dense2')(d1)\n","d3=Dense(10,activation='softmax',name='dense3')(d2)"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2021-09-16T14:16:19.828782Z","iopub.status.busy":"2021-09-16T14:16:19.828516Z","iopub.status.idle":"2021-09-16T14:16:19.843543Z","shell.execute_reply":"2021-09-16T14:16:19.842431Z","shell.execute_reply.started":"2021-09-16T14:16:19.828751Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_layer (InputLayer)    [(None, 64, 99)]          0         \n","                                                                 \n"," lstm_layer (LSTM)           (None, 64, 500)           1200000   \n","                                                                 \n"," tf.math.reduce_mean (TFOpLa  (None, 64)               0         \n"," mbda)                                                           \n","                                                                 \n"," dense1 (Dense)              (None, 120)               7800      \n","                                                                 \n"," dense2 (Dense)              (None, 60)                7260      \n","                                                                 \n"," dense3 (Dense)              (None, 10)                610       \n","                                                                 \n","=================================================================\n","Total params: 1,215,670\n","Trainable params: 1,215,670\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model = Model(inputs=input_layer, outputs=d3)\n","model.summary()"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2021-09-16T14:16:19.845847Z","iopub.status.busy":"2021-09-16T14:16:19.845411Z","iopub.status.idle":"2021-09-16T14:16:19.850832Z","shell.execute_reply":"2021-09-16T14:16:19.850051Z","shell.execute_reply.started":"2021-09-16T14:16:19.845812Z"},"trusted":true},"outputs":[],"source":["def cal_f1(y_true,y_pred):\n","    return f1_score(y_true,y_pred,average='micro')\n","def micro_f1(y_true,y_prob):\n","    y_pred=tf.math.argmax(y_prob,axis=1)\n","    return tf.py_function(cal_f1,(y_true,y_pred),tf.double)"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2021-09-16T14:16:19.853311Z","iopub.status.busy":"2021-09-16T14:16:19.852595Z","iopub.status.idle":"2021-09-16T14:16:19.860518Z","shell.execute_reply":"2021-09-16T14:16:19.859687Z","shell.execute_reply.started":"2021-09-16T14:16:19.853275Z"},"trusted":true},"outputs":[],"source":["class LossHistory(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs={}):\n","        if logs.get('val_micro_f1', -1)>0.97:\n","            self.model.stop_training=True\n","\n","loss_history=LossHistory()\n","\n","filepath=\"model_save/weights-{epoch:02d}-{micro_f1:.4f}-{val_micro_f1:.4f}.hdf5\"\n","checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=filepath, monitor='val_micro_f1',  verbose=1, save_best_only=True, mode='max')"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2021-09-16T14:16:19.862221Z","iopub.status.busy":"2021-09-16T14:16:19.861965Z","iopub.status.idle":"2021-09-16T14:16:19.879945Z","shell.execute_reply":"2021-09-16T14:16:19.879037Z","shell.execute_reply.started":"2021-09-16T14:16:19.862190Z"},"trusted":true},"outputs":[],"source":["opt= tf.keras.optimizers.Adam(learning_rate=0.001)\n","model.compile(optimizer=opt, loss='sparse_categorical_crossentropy' ,metrics=['accuracy',micro_f1])"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2021-09-16T14:16:19.881848Z","iopub.status.busy":"2021-09-16T14:16:19.881504Z","iopub.status.idle":"2021-09-16T14:23:44.478443Z","shell.execute_reply":"2021-09-16T14:23:44.477771Z","shell.execute_reply.started":"2021-09-16T14:16:19.881811Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/400\n","66/66 [==============================] - ETA: 0s - loss: 2.3022 - accuracy: 0.1029 - micro_f1: 0.1034\n","Epoch 1: val_micro_f1 improved from -inf to 0.09698, saving model to model_save\\weights-01-0.1034-0.0970.hdf5\n","66/66 [==============================] - 23s 312ms/step - loss: 2.3022 - accuracy: 0.1029 - micro_f1: 0.1034 - val_loss: 2.3013 - val_accuracy: 0.1000 - val_micro_f1: 0.0970\n","Epoch 2/400\n","66/66 [==============================] - ETA: 0s - loss: 2.3011 - accuracy: 0.0967 - micro_f1: 0.0967\n","Epoch 2: val_micro_f1 did not improve from 0.09698\n","66/66 [==============================] - 20s 309ms/step - loss: 2.3011 - accuracy: 0.0967 - micro_f1: 0.0967 - val_loss: 2.2991 - val_accuracy: 0.1000 - val_micro_f1: 0.0970\n","Epoch 3/400\n","66/66 [==============================] - ETA: 0s - loss: 2.2981 - accuracy: 0.1171 - micro_f1: 0.1168\n","Epoch 3: val_micro_f1 improved from 0.09698 to 0.14763, saving model to model_save\\weights-03-0.1168-0.1476.hdf5\n","66/66 [==============================] - 20s 299ms/step - loss: 2.2981 - accuracy: 0.1171 - micro_f1: 0.1168 - val_loss: 2.2941 - val_accuracy: 0.1522 - val_micro_f1: 0.1476\n","Epoch 4/400\n","66/66 [==============================] - ETA: 0s - loss: 2.2935 - accuracy: 0.1114 - micro_f1: 0.1116\n","Epoch 4: val_micro_f1 did not improve from 0.14763\n","66/66 [==============================] - 22s 341ms/step - loss: 2.2935 - accuracy: 0.1114 - micro_f1: 0.1116 - val_loss: 2.2848 - val_accuracy: 0.1156 - val_micro_f1: 0.1121\n","Epoch 5/400\n","66/66 [==============================] - ETA: 0s - loss: 2.2828 - accuracy: 0.1514 - micro_f1: 0.1517\n","Epoch 5: val_micro_f1 improved from 0.14763 to 0.18427, saving model to model_save\\weights-05-0.1517-0.1843.hdf5\n","66/66 [==============================] - 22s 341ms/step - loss: 2.2828 - accuracy: 0.1514 - micro_f1: 0.1517 - val_loss: 2.2729 - val_accuracy: 0.1900 - val_micro_f1: 0.1843\n","Epoch 6/400\n","66/66 [==============================] - ETA: 0s - loss: 2.2654 - accuracy: 0.1538 - micro_f1: 0.1546\n","Epoch 6: val_micro_f1 did not improve from 0.18427\n","66/66 [==============================] - 20s 303ms/step - loss: 2.2654 - accuracy: 0.1538 - micro_f1: 0.1546 - val_loss: 2.2453 - val_accuracy: 0.1856 - val_micro_f1: 0.1800\n","Epoch 7/400\n","66/66 [==============================] - ETA: 0s - loss: 2.2436 - accuracy: 0.1529 - micro_f1: 0.1526\n","Epoch 7: val_micro_f1 did not improve from 0.18427\n","66/66 [==============================] - 19s 296ms/step - loss: 2.2436 - accuracy: 0.1529 - micro_f1: 0.1526 - val_loss: 2.2300 - val_accuracy: 0.1222 - val_micro_f1: 0.1185\n","Epoch 8/400\n","66/66 [==============================] - ETA: 0s - loss: 2.2090 - accuracy: 0.1776 - micro_f1: 0.1783\n","Epoch 8: val_micro_f1 did not improve from 0.18427\n","66/66 [==============================] - 19s 286ms/step - loss: 2.2090 - accuracy: 0.1776 - micro_f1: 0.1783 - val_loss: 2.2083 - val_accuracy: 0.1800 - val_micro_f1: 0.1746\n","Epoch 9/400\n","66/66 [==============================] - ETA: 0s - loss: 2.1721 - accuracy: 0.1786 - micro_f1: 0.1778\n","Epoch 9: val_micro_f1 did not improve from 0.18427\n","66/66 [==============================] - 18s 279ms/step - loss: 2.1721 - accuracy: 0.1786 - micro_f1: 0.1778 - val_loss: 2.1415 - val_accuracy: 0.1767 - val_micro_f1: 0.1713\n","Epoch 10/400\n","66/66 [==============================] - ETA: 0s - loss: 2.1389 - accuracy: 0.1771 - micro_f1: 0.1767\n","Epoch 10: val_micro_f1 improved from 0.18427 to 0.25970, saving model to model_save\\weights-10-0.1767-0.2597.hdf5\n","66/66 [==============================] - 20s 311ms/step - loss: 2.1389 - accuracy: 0.1771 - micro_f1: 0.1767 - val_loss: 2.1085 - val_accuracy: 0.2678 - val_micro_f1: 0.2597\n","Epoch 11/400\n","66/66 [==============================] - ETA: 0s - loss: 2.0892 - accuracy: 0.2105 - micro_f1: 0.2104\n","Epoch 11: val_micro_f1 did not improve from 0.25970\n","66/66 [==============================] - 18s 280ms/step - loss: 2.0892 - accuracy: 0.2105 - micro_f1: 0.2104 - val_loss: 2.0516 - val_accuracy: 0.2322 - val_micro_f1: 0.2252\n","Epoch 12/400\n","66/66 [==============================] - ETA: 0s - loss: 2.0638 - accuracy: 0.2076 - micro_f1: 0.2087\n","Epoch 12: val_micro_f1 did not improve from 0.25970\n","66/66 [==============================] - 19s 285ms/step - loss: 2.0638 - accuracy: 0.2076 - micro_f1: 0.2087 - val_loss: 2.0133 - val_accuracy: 0.2467 - val_micro_f1: 0.2468\n","Epoch 13/400\n","66/66 [==============================] - ETA: 0s - loss: 2.0915 - accuracy: 0.1933 - micro_f1: 0.1928\n","Epoch 13: val_micro_f1 did not improve from 0.25970\n","66/66 [==============================] - 19s 296ms/step - loss: 2.0915 - accuracy: 0.1933 - micro_f1: 0.1928 - val_loss: 2.0330 - val_accuracy: 0.2233 - val_micro_f1: 0.2166\n","Epoch 14/400\n","66/66 [==============================] - ETA: 0s - loss: 2.0221 - accuracy: 0.2262 - micro_f1: 0.2258\n","Epoch 14: val_micro_f1 did not improve from 0.25970\n","66/66 [==============================] - 19s 289ms/step - loss: 2.0221 - accuracy: 0.2262 - micro_f1: 0.2258 - val_loss: 1.9896 - val_accuracy: 0.2356 - val_micro_f1: 0.2360\n","Epoch 15/400\n","66/66 [==============================] - ETA: 0s - loss: 1.9913 - accuracy: 0.2290 - micro_f1: 0.2286\n","Epoch 15: val_micro_f1 did not improve from 0.25970\n","66/66 [==============================] - 18s 280ms/step - loss: 1.9913 - accuracy: 0.2290 - micro_f1: 0.2286 - val_loss: 1.9771 - val_accuracy: 0.2289 - val_micro_f1: 0.2371\n","Epoch 16/400\n","66/66 [==============================] - ETA: 0s - loss: 1.9855 - accuracy: 0.2186 - micro_f1: 0.2182\n","Epoch 16: val_micro_f1 did not improve from 0.25970\n","66/66 [==============================] - 21s 326ms/step - loss: 1.9855 - accuracy: 0.2186 - micro_f1: 0.2182 - val_loss: 2.0121 - val_accuracy: 0.2322 - val_micro_f1: 0.2403\n","Epoch 17/400\n","66/66 [==============================] - ETA: 0s - loss: 1.9798 - accuracy: 0.2252 - micro_f1: 0.2257\n","Epoch 17: val_micro_f1 did not improve from 0.25970\n","66/66 [==============================] - 21s 324ms/step - loss: 1.9798 - accuracy: 0.2252 - micro_f1: 0.2257 - val_loss: 2.0788 - val_accuracy: 0.1911 - val_micro_f1: 0.2004\n","Epoch 18/400\n","66/66 [==============================] - ETA: 0s - loss: 1.9625 - accuracy: 0.2281 - micro_f1: 0.2279\n","Epoch 18: val_micro_f1 improved from 0.25970 to 0.27263, saving model to model_save\\weights-18-0.2279-0.2726.hdf5\n","66/66 [==============================] - 21s 318ms/step - loss: 1.9625 - accuracy: 0.2281 - micro_f1: 0.2279 - val_loss: 1.9114 - val_accuracy: 0.2733 - val_micro_f1: 0.2726\n","Epoch 19/400\n","66/66 [==============================] - ETA: 0s - loss: 1.9533 - accuracy: 0.2200 - micro_f1: 0.2202\n","Epoch 19: val_micro_f1 did not improve from 0.27263\n","66/66 [==============================] - 20s 308ms/step - loss: 1.9533 - accuracy: 0.2200 - micro_f1: 0.2202 - val_loss: 1.9107 - val_accuracy: 0.2311 - val_micro_f1: 0.2317\n","Epoch 20/400\n","66/66 [==============================] - ETA: 0s - loss: 1.9423 - accuracy: 0.2371 - micro_f1: 0.2369\n","Epoch 20: val_micro_f1 improved from 0.27263 to 0.28125, saving model to model_save\\weights-20-0.2369-0.2812.hdf5\n","66/66 [==============================] - 21s 315ms/step - loss: 1.9423 - accuracy: 0.2371 - micro_f1: 0.2369 - val_loss: 1.9037 - val_accuracy: 0.2822 - val_micro_f1: 0.2812\n","Epoch 21/400\n","66/66 [==============================] - ETA: 0s - loss: 1.9350 - accuracy: 0.2429 - micro_f1: 0.2426\n","Epoch 21: val_micro_f1 did not improve from 0.28125\n","66/66 [==============================] - 19s 292ms/step - loss: 1.9350 - accuracy: 0.2429 - micro_f1: 0.2426 - val_loss: 1.8916 - val_accuracy: 0.2400 - val_micro_f1: 0.2328\n","Epoch 22/400\n","66/66 [==============================] - ETA: 0s - loss: 1.9449 - accuracy: 0.2324 - micro_f1: 0.2322\n","Epoch 22: val_micro_f1 did not improve from 0.28125\n","66/66 [==============================] - 19s 295ms/step - loss: 1.9449 - accuracy: 0.2324 - micro_f1: 0.2322 - val_loss: 1.8884 - val_accuracy: 0.2800 - val_micro_f1: 0.2791\n","Epoch 23/400\n","66/66 [==============================] - ETA: 0s - loss: 1.9447 - accuracy: 0.2457 - micro_f1: 0.2469\n","Epoch 23: val_micro_f1 did not improve from 0.28125\n","66/66 [==============================] - 19s 293ms/step - loss: 1.9447 - accuracy: 0.2457 - micro_f1: 0.2469 - val_loss: 1.8840 - val_accuracy: 0.2811 - val_micro_f1: 0.2726\n","Epoch 24/400\n","66/66 [==============================] - ETA: 0s - loss: 1.9110 - accuracy: 0.2429 - micro_f1: 0.2429\n","Epoch 24: val_micro_f1 did not improve from 0.28125\n","66/66 [==============================] - 23s 345ms/step - loss: 1.9110 - accuracy: 0.2429 - micro_f1: 0.2429 - val_loss: 1.8670 - val_accuracy: 0.2578 - val_micro_f1: 0.2500\n","Epoch 25/400\n","66/66 [==============================] - ETA: 0s - loss: 1.9433 - accuracy: 0.2186 - micro_f1: 0.2185\n","Epoch 25: val_micro_f1 did not improve from 0.28125\n","66/66 [==============================] - 22s 342ms/step - loss: 1.9433 - accuracy: 0.2186 - micro_f1: 0.2185 - val_loss: 1.9080 - val_accuracy: 0.2356 - val_micro_f1: 0.2284\n","Epoch 26/400\n","66/66 [==============================] - ETA: 0s - loss: 1.9214 - accuracy: 0.2433 - micro_f1: 0.2428\n","Epoch 26: val_micro_f1 did not improve from 0.28125\n","66/66 [==============================] - 19s 289ms/step - loss: 1.9214 - accuracy: 0.2433 - micro_f1: 0.2428 - val_loss: 1.9892 - val_accuracy: 0.1878 - val_micro_f1: 0.1821\n","Epoch 27/400\n","66/66 [==============================] - ETA: 0s - loss: 1.9101 - accuracy: 0.2414 - micro_f1: 0.2420\n","Epoch 27: val_micro_f1 improved from 0.28125 to 0.28879, saving model to model_save\\weights-27-0.2420-0.2888.hdf5\n","66/66 [==============================] - 21s 326ms/step - loss: 1.9101 - accuracy: 0.2414 - micro_f1: 0.2420 - val_loss: 1.8773 - val_accuracy: 0.2822 - val_micro_f1: 0.2888\n","Epoch 28/400\n","66/66 [==============================] - ETA: 0s - loss: 1.9048 - accuracy: 0.2357 - micro_f1: 0.2358\n","Epoch 28: val_micro_f1 improved from 0.28879 to 0.32220, saving model to model_save\\weights-28-0.2358-0.3222.hdf5\n","66/66 [==============================] - 19s 290ms/step - loss: 1.9048 - accuracy: 0.2357 - micro_f1: 0.2358 - val_loss: 1.9027 - val_accuracy: 0.3244 - val_micro_f1: 0.3222\n","Epoch 29/400\n","66/66 [==============================] - ETA: 0s - loss: 1.9073 - accuracy: 0.2476 - micro_f1: 0.2476\n","Epoch 29: val_micro_f1 did not improve from 0.32220\n","66/66 [==============================] - 19s 289ms/step - loss: 1.9073 - accuracy: 0.2476 - micro_f1: 0.2476 - val_loss: 1.9150 - val_accuracy: 0.2256 - val_micro_f1: 0.2188\n","Epoch 30/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8953 - accuracy: 0.2576 - micro_f1: 0.2570\n","Epoch 30: val_micro_f1 did not improve from 0.32220\n","66/66 [==============================] - 19s 295ms/step - loss: 1.8953 - accuracy: 0.2576 - micro_f1: 0.2570 - val_loss: 1.8493 - val_accuracy: 0.3156 - val_micro_f1: 0.3136\n","Epoch 31/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8791 - accuracy: 0.2581 - micro_f1: 0.2578\n","Epoch 31: val_micro_f1 did not improve from 0.32220\n","66/66 [==============================] - 19s 292ms/step - loss: 1.8791 - accuracy: 0.2581 - micro_f1: 0.2578 - val_loss: 1.8584 - val_accuracy: 0.2978 - val_micro_f1: 0.2963\n","Epoch 32/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8886 - accuracy: 0.2600 - micro_f1: 0.2614\n","Epoch 32: val_micro_f1 did not improve from 0.32220\n","66/66 [==============================] - 19s 295ms/step - loss: 1.8886 - accuracy: 0.2600 - micro_f1: 0.2614 - val_loss: 1.9114 - val_accuracy: 0.2244 - val_micro_f1: 0.2177\n","Epoch 33/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8873 - accuracy: 0.2524 - micro_f1: 0.2524\n","Epoch 33: val_micro_f1 did not improve from 0.32220\n","66/66 [==============================] - 19s 288ms/step - loss: 1.8873 - accuracy: 0.2524 - micro_f1: 0.2524 - val_loss: 1.8418 - val_accuracy: 0.2933 - val_micro_f1: 0.2920\n","Epoch 34/400\n","66/66 [==============================] - ETA: 0s - loss: 1.9011 - accuracy: 0.2576 - micro_f1: 0.2581\n","Epoch 34: val_micro_f1 did not improve from 0.32220\n","66/66 [==============================] - 21s 319ms/step - loss: 1.9011 - accuracy: 0.2576 - micro_f1: 0.2581 - val_loss: 1.8458 - val_accuracy: 0.2533 - val_micro_f1: 0.2457\n","Epoch 35/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8991 - accuracy: 0.2486 - micro_f1: 0.2486\n","Epoch 35: val_micro_f1 did not improve from 0.32220\n","66/66 [==============================] - 19s 287ms/step - loss: 1.8991 - accuracy: 0.2486 - micro_f1: 0.2486 - val_loss: 1.8479 - val_accuracy: 0.3167 - val_micro_f1: 0.3071\n","Epoch 36/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8530 - accuracy: 0.2762 - micro_f1: 0.2760\n","Epoch 36: val_micro_f1 did not improve from 0.32220\n","66/66 [==============================] - 19s 283ms/step - loss: 1.8530 - accuracy: 0.2762 - micro_f1: 0.2760 - val_loss: 1.8296 - val_accuracy: 0.2589 - val_micro_f1: 0.2586\n","Epoch 37/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8695 - accuracy: 0.2662 - micro_f1: 0.2664\n","Epoch 37: val_micro_f1 did not improve from 0.32220\n","66/66 [==============================] - 21s 326ms/step - loss: 1.8695 - accuracy: 0.2662 - micro_f1: 0.2664 - val_loss: 1.8242 - val_accuracy: 0.2378 - val_micro_f1: 0.2381\n","Epoch 38/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8621 - accuracy: 0.2595 - micro_f1: 0.2589\n","Epoch 38: val_micro_f1 did not improve from 0.32220\n","66/66 [==============================] - 19s 289ms/step - loss: 1.8621 - accuracy: 0.2595 - micro_f1: 0.2589 - val_loss: 1.8567 - val_accuracy: 0.2511 - val_micro_f1: 0.2511\n","Epoch 39/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8780 - accuracy: 0.2395 - micro_f1: 0.2393\n","Epoch 39: val_micro_f1 did not improve from 0.32220\n","66/66 [==============================] - 22s 330ms/step - loss: 1.8780 - accuracy: 0.2395 - micro_f1: 0.2393 - val_loss: 1.8406 - val_accuracy: 0.2722 - val_micro_f1: 0.2640\n","Epoch 40/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8540 - accuracy: 0.2790 - micro_f1: 0.2797\n","Epoch 40: val_micro_f1 did not improve from 0.32220\n","66/66 [==============================] - 21s 313ms/step - loss: 1.8540 - accuracy: 0.2790 - micro_f1: 0.2797 - val_loss: 1.8904 - val_accuracy: 0.2222 - val_micro_f1: 0.2155\n","Epoch 41/400\n","66/66 [==============================] - ETA: 0s - loss: 1.9029 - accuracy: 0.2567 - micro_f1: 0.2572\n","Epoch 41: val_micro_f1 did not improve from 0.32220\n","66/66 [==============================] - 20s 310ms/step - loss: 1.9029 - accuracy: 0.2567 - micro_f1: 0.2572 - val_loss: 1.8157 - val_accuracy: 0.2711 - val_micro_f1: 0.2705\n","Epoch 42/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8516 - accuracy: 0.2781 - micro_f1: 0.2768\n","Epoch 42: val_micro_f1 did not improve from 0.32220\n","66/66 [==============================] - 21s 320ms/step - loss: 1.8516 - accuracy: 0.2781 - micro_f1: 0.2768 - val_loss: 1.8157 - val_accuracy: 0.2478 - val_micro_f1: 0.2403\n","Epoch 43/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8648 - accuracy: 0.2638 - micro_f1: 0.2634\n","Epoch 43: val_micro_f1 did not improve from 0.32220\n","66/66 [==============================] - 20s 299ms/step - loss: 1.8648 - accuracy: 0.2638 - micro_f1: 0.2634 - val_loss: 1.8294 - val_accuracy: 0.2856 - val_micro_f1: 0.2845\n","Epoch 44/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8543 - accuracy: 0.2648 - micro_f1: 0.2644\n","Epoch 44: val_micro_f1 did not improve from 0.32220\n","66/66 [==============================] - 18s 271ms/step - loss: 1.8543 - accuracy: 0.2648 - micro_f1: 0.2644 - val_loss: 1.8495 - val_accuracy: 0.2833 - val_micro_f1: 0.2748\n","Epoch 45/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8634 - accuracy: 0.2581 - micro_f1: 0.2583\n","Epoch 45: val_micro_f1 did not improve from 0.32220\n","66/66 [==============================] - 18s 272ms/step - loss: 1.8634 - accuracy: 0.2581 - micro_f1: 0.2583 - val_loss: 1.8150 - val_accuracy: 0.2767 - val_micro_f1: 0.2834\n","Epoch 46/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8346 - accuracy: 0.2805 - micro_f1: 0.2792\n","Epoch 46: val_micro_f1 did not improve from 0.32220\n","66/66 [==============================] - 19s 287ms/step - loss: 1.8346 - accuracy: 0.2805 - micro_f1: 0.2792 - val_loss: 1.8082 - val_accuracy: 0.2789 - val_micro_f1: 0.2705\n","Epoch 47/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8421 - accuracy: 0.2695 - micro_f1: 0.2708\n","Epoch 47: val_micro_f1 did not improve from 0.32220\n","66/66 [==============================] - 19s 290ms/step - loss: 1.8421 - accuracy: 0.2695 - micro_f1: 0.2708 - val_loss: 1.8528 - val_accuracy: 0.2544 - val_micro_f1: 0.2468\n","Epoch 48/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8425 - accuracy: 0.2852 - micro_f1: 0.2862\n","Epoch 48: val_micro_f1 did not improve from 0.32220\n","66/66 [==============================] - 19s 293ms/step - loss: 1.8425 - accuracy: 0.2852 - micro_f1: 0.2862 - val_loss: 1.8769 - val_accuracy: 0.2378 - val_micro_f1: 0.2306\n","Epoch 49/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8376 - accuracy: 0.2838 - micro_f1: 0.2833\n","Epoch 49: val_micro_f1 did not improve from 0.32220\n","66/66 [==============================] - 22s 341ms/step - loss: 1.8376 - accuracy: 0.2838 - micro_f1: 0.2833 - val_loss: 1.7949 - val_accuracy: 0.2644 - val_micro_f1: 0.2640\n","Epoch 50/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8280 - accuracy: 0.2795 - micro_f1: 0.2794\n","Epoch 50: val_micro_f1 did not improve from 0.32220\n","66/66 [==============================] - 21s 320ms/step - loss: 1.8280 - accuracy: 0.2795 - micro_f1: 0.2794 - val_loss: 1.8094 - val_accuracy: 0.2356 - val_micro_f1: 0.2360\n","Epoch 51/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8436 - accuracy: 0.2667 - micro_f1: 0.2660\n","Epoch 51: val_micro_f1 did not improve from 0.32220\n","66/66 [==============================] - 22s 337ms/step - loss: 1.8436 - accuracy: 0.2667 - micro_f1: 0.2660 - val_loss: 1.8032 - val_accuracy: 0.2933 - val_micro_f1: 0.2920\n","Epoch 52/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8707 - accuracy: 0.2700 - micro_f1: 0.2702\n","Epoch 52: val_micro_f1 did not improve from 0.32220\n","66/66 [==============================] - 22s 329ms/step - loss: 1.8707 - accuracy: 0.2700 - micro_f1: 0.2702 - val_loss: 1.8000 - val_accuracy: 0.2556 - val_micro_f1: 0.2554\n","Epoch 53/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8667 - accuracy: 0.2524 - micro_f1: 0.2518\n","Epoch 53: val_micro_f1 did not improve from 0.32220\n","66/66 [==============================] - 22s 340ms/step - loss: 1.8667 - accuracy: 0.2524 - micro_f1: 0.2518 - val_loss: 1.8081 - val_accuracy: 0.2589 - val_micro_f1: 0.2511\n","Epoch 54/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8266 - accuracy: 0.2824 - micro_f1: 0.2819\n","Epoch 54: val_micro_f1 improved from 0.32220 to 0.34052, saving model to model_save\\weights-54-0.2819-0.3405.hdf5\n","66/66 [==============================] - 22s 333ms/step - loss: 1.8266 - accuracy: 0.2824 - micro_f1: 0.2819 - val_loss: 1.7813 - val_accuracy: 0.3356 - val_micro_f1: 0.3405\n","Epoch 55/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8620 - accuracy: 0.2524 - micro_f1: 0.2527\n","Epoch 55: val_micro_f1 did not improve from 0.34052\n","66/66 [==============================] - 21s 316ms/step - loss: 1.8620 - accuracy: 0.2524 - micro_f1: 0.2527 - val_loss: 1.7725 - val_accuracy: 0.3133 - val_micro_f1: 0.3039\n","Epoch 56/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8296 - accuracy: 0.2743 - micro_f1: 0.2733\n","Epoch 56: val_micro_f1 did not improve from 0.34052\n","66/66 [==============================] - 21s 313ms/step - loss: 1.8296 - accuracy: 0.2743 - micro_f1: 0.2733 - val_loss: 1.7914 - val_accuracy: 0.2911 - val_micro_f1: 0.2899\n","Epoch 57/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8718 - accuracy: 0.2595 - micro_f1: 0.2595\n","Epoch 57: val_micro_f1 did not improve from 0.34052\n","66/66 [==============================] - 20s 309ms/step - loss: 1.8718 - accuracy: 0.2595 - micro_f1: 0.2595 - val_loss: 1.8689 - val_accuracy: 0.2778 - val_micro_f1: 0.2694\n","Epoch 58/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8220 - accuracy: 0.2643 - micro_f1: 0.2648\n","Epoch 58: val_micro_f1 did not improve from 0.34052\n","66/66 [==============================] - 22s 339ms/step - loss: 1.8220 - accuracy: 0.2643 - micro_f1: 0.2648 - val_loss: 1.7894 - val_accuracy: 0.2811 - val_micro_f1: 0.2802\n","Epoch 59/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8463 - accuracy: 0.2690 - micro_f1: 0.2692\n","Epoch 59: val_micro_f1 did not improve from 0.34052\n","66/66 [==============================] - 22s 329ms/step - loss: 1.8463 - accuracy: 0.2690 - micro_f1: 0.2692 - val_loss: 1.8876 - val_accuracy: 0.2433 - val_micro_f1: 0.2360\n","Epoch 60/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8277 - accuracy: 0.2805 - micro_f1: 0.2795\n","Epoch 60: val_micro_f1 did not improve from 0.34052\n","66/66 [==============================] - 21s 313ms/step - loss: 1.8277 - accuracy: 0.2805 - micro_f1: 0.2795 - val_loss: 1.8331 - val_accuracy: 0.2656 - val_micro_f1: 0.2575\n","Epoch 61/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8414 - accuracy: 0.2538 - micro_f1: 0.2541\n","Epoch 61: val_micro_f1 did not improve from 0.34052\n","66/66 [==============================] - 22s 340ms/step - loss: 1.8414 - accuracy: 0.2538 - micro_f1: 0.2541 - val_loss: 1.7782 - val_accuracy: 0.2933 - val_micro_f1: 0.2845\n","Epoch 62/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8343 - accuracy: 0.2724 - micro_f1: 0.2723\n","Epoch 62: val_micro_f1 did not improve from 0.34052\n","66/66 [==============================] - 22s 338ms/step - loss: 1.8343 - accuracy: 0.2724 - micro_f1: 0.2723 - val_loss: 1.9668 - val_accuracy: 0.2067 - val_micro_f1: 0.2004\n","Epoch 63/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8282 - accuracy: 0.2662 - micro_f1: 0.2670\n","Epoch 63: val_micro_f1 did not improve from 0.34052\n","66/66 [==============================] - 22s 334ms/step - loss: 1.8282 - accuracy: 0.2662 - micro_f1: 0.2670 - val_loss: 2.0795 - val_accuracy: 0.1667 - val_micro_f1: 0.1616\n","Epoch 64/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8988 - accuracy: 0.2443 - micro_f1: 0.2455\n","Epoch 64: val_micro_f1 did not improve from 0.34052\n","66/66 [==============================] - 22s 338ms/step - loss: 1.8988 - accuracy: 0.2443 - micro_f1: 0.2455 - val_loss: 1.7815 - val_accuracy: 0.2844 - val_micro_f1: 0.2834\n","Epoch 65/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8231 - accuracy: 0.2862 - micro_f1: 0.2868\n","Epoch 65: val_micro_f1 did not improve from 0.34052\n","66/66 [==============================] - 22s 335ms/step - loss: 1.8231 - accuracy: 0.2862 - micro_f1: 0.2868 - val_loss: 1.7845 - val_accuracy: 0.2944 - val_micro_f1: 0.2931\n","Epoch 66/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8082 - accuracy: 0.2938 - micro_f1: 0.2938\n","Epoch 66: val_micro_f1 did not improve from 0.34052\n","66/66 [==============================] - 22s 339ms/step - loss: 1.8082 - accuracy: 0.2938 - micro_f1: 0.2938 - val_loss: 1.7710 - val_accuracy: 0.2533 - val_micro_f1: 0.2457\n","Epoch 67/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8217 - accuracy: 0.2867 - micro_f1: 0.2859\n","Epoch 67: val_micro_f1 did not improve from 0.34052\n","66/66 [==============================] - 22s 335ms/step - loss: 1.8217 - accuracy: 0.2867 - micro_f1: 0.2859 - val_loss: 1.7963 - val_accuracy: 0.2867 - val_micro_f1: 0.2856\n","Epoch 68/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8273 - accuracy: 0.2643 - micro_f1: 0.2642\n","Epoch 68: val_micro_f1 did not improve from 0.34052\n","66/66 [==============================] - 24s 358ms/step - loss: 1.8273 - accuracy: 0.2643 - micro_f1: 0.2642 - val_loss: 1.7749 - val_accuracy: 0.3211 - val_micro_f1: 0.3265\n","Epoch 69/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8136 - accuracy: 0.2848 - micro_f1: 0.2843\n","Epoch 69: val_micro_f1 improved from 0.34052 to 0.34375, saving model to model_save\\weights-69-0.2843-0.3438.hdf5\n","66/66 [==============================] - 22s 338ms/step - loss: 1.8136 - accuracy: 0.2848 - micro_f1: 0.2843 - val_loss: 1.7988 - val_accuracy: 0.3467 - val_micro_f1: 0.3438\n","Epoch 70/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8145 - accuracy: 0.2690 - micro_f1: 0.2701\n","Epoch 70: val_micro_f1 did not improve from 0.34375\n","66/66 [==============================] - 24s 364ms/step - loss: 1.8145 - accuracy: 0.2690 - micro_f1: 0.2701 - val_loss: 1.8465 - val_accuracy: 0.2478 - val_micro_f1: 0.2403\n","Epoch 71/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8096 - accuracy: 0.2695 - micro_f1: 0.2697\n","Epoch 71: val_micro_f1 did not improve from 0.34375\n","66/66 [==============================] - 22s 339ms/step - loss: 1.8096 - accuracy: 0.2695 - micro_f1: 0.2697 - val_loss: 1.7620 - val_accuracy: 0.3111 - val_micro_f1: 0.3017\n","Epoch 72/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7994 - accuracy: 0.2905 - micro_f1: 0.2908\n","Epoch 72: val_micro_f1 did not improve from 0.34375\n","66/66 [==============================] - 22s 336ms/step - loss: 1.7994 - accuracy: 0.2905 - micro_f1: 0.2908 - val_loss: 1.7504 - val_accuracy: 0.3111 - val_micro_f1: 0.3017\n","Epoch 73/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8142 - accuracy: 0.2962 - micro_f1: 0.2959\n","Epoch 73: val_micro_f1 did not improve from 0.34375\n","66/66 [==============================] - 22s 341ms/step - loss: 1.8142 - accuracy: 0.2962 - micro_f1: 0.2959 - val_loss: 1.8590 - val_accuracy: 0.2522 - val_micro_f1: 0.2446\n","Epoch 74/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7976 - accuracy: 0.2771 - micro_f1: 0.2770\n","Epoch 74: val_micro_f1 did not improve from 0.34375\n","66/66 [==============================] - 23s 343ms/step - loss: 1.7976 - accuracy: 0.2771 - micro_f1: 0.2770 - val_loss: 1.7597 - val_accuracy: 0.3289 - val_micro_f1: 0.3265\n","Epoch 75/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8146 - accuracy: 0.2848 - micro_f1: 0.2851\n","Epoch 75: val_micro_f1 did not improve from 0.34375\n","66/66 [==============================] - 23s 347ms/step - loss: 1.8146 - accuracy: 0.2848 - micro_f1: 0.2851 - val_loss: 1.9606 - val_accuracy: 0.2256 - val_micro_f1: 0.2188\n","Epoch 76/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8312 - accuracy: 0.2738 - micro_f1: 0.2731\n","Epoch 76: val_micro_f1 did not improve from 0.34375\n","66/66 [==============================] - 23s 344ms/step - loss: 1.8312 - accuracy: 0.2738 - micro_f1: 0.2731 - val_loss: 1.8129 - val_accuracy: 0.2567 - val_micro_f1: 0.2489\n","Epoch 77/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7966 - accuracy: 0.2776 - micro_f1: 0.2775\n","Epoch 77: val_micro_f1 did not improve from 0.34375\n","66/66 [==============================] - 23s 344ms/step - loss: 1.7966 - accuracy: 0.2776 - micro_f1: 0.2775 - val_loss: 1.7552 - val_accuracy: 0.3133 - val_micro_f1: 0.3114\n","Epoch 78/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8407 - accuracy: 0.2538 - micro_f1: 0.2546\n","Epoch 78: val_micro_f1 did not improve from 0.34375\n","66/66 [==============================] - 23s 345ms/step - loss: 1.8407 - accuracy: 0.2538 - micro_f1: 0.2546 - val_loss: 1.7968 - val_accuracy: 0.3078 - val_micro_f1: 0.3060\n","Epoch 79/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7951 - accuracy: 0.2805 - micro_f1: 0.2812\n","Epoch 79: val_micro_f1 did not improve from 0.34375\n","66/66 [==============================] - 22s 332ms/step - loss: 1.7951 - accuracy: 0.2805 - micro_f1: 0.2812 - val_loss: 1.7689 - val_accuracy: 0.2789 - val_micro_f1: 0.2705\n","Epoch 80/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7925 - accuracy: 0.2967 - micro_f1: 0.2970\n","Epoch 80: val_micro_f1 did not improve from 0.34375\n","66/66 [==============================] - 21s 326ms/step - loss: 1.7925 - accuracy: 0.2967 - micro_f1: 0.2970 - val_loss: 1.7525 - val_accuracy: 0.3344 - val_micro_f1: 0.3244\n","Epoch 81/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7770 - accuracy: 0.3090 - micro_f1: 0.3090\n","Epoch 81: val_micro_f1 did not improve from 0.34375\n","66/66 [==============================] - 22s 340ms/step - loss: 1.7770 - accuracy: 0.3090 - micro_f1: 0.3090 - val_loss: 1.7384 - val_accuracy: 0.2722 - val_micro_f1: 0.2716\n","Epoch 82/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7763 - accuracy: 0.2995 - micro_f1: 0.2990\n","Epoch 82: val_micro_f1 did not improve from 0.34375\n","66/66 [==============================] - 23s 343ms/step - loss: 1.7763 - accuracy: 0.2995 - micro_f1: 0.2990 - val_loss: 1.7497 - val_accuracy: 0.2656 - val_micro_f1: 0.2651\n","Epoch 83/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8197 - accuracy: 0.2781 - micro_f1: 0.2779\n","Epoch 83: val_micro_f1 did not improve from 0.34375\n","66/66 [==============================] - 22s 339ms/step - loss: 1.8197 - accuracy: 0.2781 - micro_f1: 0.2779 - val_loss: 1.8656 - val_accuracy: 0.2689 - val_micro_f1: 0.2608\n","Epoch 84/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7973 - accuracy: 0.2776 - micro_f1: 0.2769\n","Epoch 84: val_micro_f1 did not improve from 0.34375\n","66/66 [==============================] - 23s 347ms/step - loss: 1.7973 - accuracy: 0.2776 - micro_f1: 0.2769 - val_loss: 1.8271 - val_accuracy: 0.2500 - val_micro_f1: 0.2425\n","Epoch 85/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8243 - accuracy: 0.2710 - micro_f1: 0.2711\n","Epoch 85: val_micro_f1 did not improve from 0.34375\n","66/66 [==============================] - 24s 362ms/step - loss: 1.8243 - accuracy: 0.2710 - micro_f1: 0.2711 - val_loss: 1.7502 - val_accuracy: 0.2967 - val_micro_f1: 0.2953\n","Epoch 86/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7992 - accuracy: 0.3038 - micro_f1: 0.3032\n","Epoch 86: val_micro_f1 did not improve from 0.34375\n","66/66 [==============================] - 24s 358ms/step - loss: 1.7992 - accuracy: 0.3038 - micro_f1: 0.3032 - val_loss: 1.9114 - val_accuracy: 0.2200 - val_micro_f1: 0.2134\n","Epoch 87/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8094 - accuracy: 0.3090 - micro_f1: 0.3087\n","Epoch 87: val_micro_f1 did not improve from 0.34375\n","66/66 [==============================] - 24s 357ms/step - loss: 1.8094 - accuracy: 0.3090 - micro_f1: 0.3087 - val_loss: 1.9280 - val_accuracy: 0.2544 - val_micro_f1: 0.2468\n","Epoch 88/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8297 - accuracy: 0.2795 - micro_f1: 0.2799\n","Epoch 88: val_micro_f1 improved from 0.34375 to 0.37931, saving model to model_save\\weights-88-0.2799-0.3793.hdf5\n","66/66 [==============================] - 23s 348ms/step - loss: 1.8297 - accuracy: 0.2795 - micro_f1: 0.2799 - val_loss: 1.7356 - val_accuracy: 0.3756 - val_micro_f1: 0.3793\n","Epoch 89/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7985 - accuracy: 0.2962 - micro_f1: 0.2962\n","Epoch 89: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 24s 358ms/step - loss: 1.7985 - accuracy: 0.2962 - micro_f1: 0.2962 - val_loss: 1.7558 - val_accuracy: 0.3178 - val_micro_f1: 0.3157\n","Epoch 90/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7948 - accuracy: 0.2933 - micro_f1: 0.2931\n","Epoch 90: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 24s 360ms/step - loss: 1.7948 - accuracy: 0.2933 - micro_f1: 0.2931 - val_loss: 1.9280 - val_accuracy: 0.2267 - val_micro_f1: 0.2198\n","Epoch 91/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8416 - accuracy: 0.2686 - micro_f1: 0.2682\n","Epoch 91: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 23s 348ms/step - loss: 1.8416 - accuracy: 0.2686 - micro_f1: 0.2682 - val_loss: 1.7463 - val_accuracy: 0.2944 - val_micro_f1: 0.3006\n","Epoch 92/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7691 - accuracy: 0.3110 - micro_f1: 0.3112\n","Epoch 92: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 21s 321ms/step - loss: 1.7691 - accuracy: 0.3110 - micro_f1: 0.3112 - val_loss: 1.7768 - val_accuracy: 0.3156 - val_micro_f1: 0.3136\n","Epoch 93/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7686 - accuracy: 0.2933 - micro_f1: 0.2939\n","Epoch 93: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 21s 313ms/step - loss: 1.7686 - accuracy: 0.2933 - micro_f1: 0.2939 - val_loss: 1.7240 - val_accuracy: 0.3089 - val_micro_f1: 0.3147\n","Epoch 94/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7733 - accuracy: 0.3024 - micro_f1: 0.3024\n","Epoch 94: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 22s 326ms/step - loss: 1.7733 - accuracy: 0.3024 - micro_f1: 0.3024 - val_loss: 1.7331 - val_accuracy: 0.3089 - val_micro_f1: 0.2996\n","Epoch 95/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7647 - accuracy: 0.3148 - micro_f1: 0.3158\n","Epoch 95: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 22s 330ms/step - loss: 1.7647 - accuracy: 0.3148 - micro_f1: 0.3158 - val_loss: 1.7214 - val_accuracy: 0.3644 - val_micro_f1: 0.3610\n","Epoch 96/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8368 - accuracy: 0.2752 - micro_f1: 0.2765\n","Epoch 96: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 22s 329ms/step - loss: 1.8368 - accuracy: 0.2752 - micro_f1: 0.2765 - val_loss: 1.7996 - val_accuracy: 0.2578 - val_micro_f1: 0.2575\n","Epoch 97/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7876 - accuracy: 0.3000 - micro_f1: 0.3006\n","Epoch 97: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 22s 327ms/step - loss: 1.7876 - accuracy: 0.3000 - micro_f1: 0.3006 - val_loss: 1.7321 - val_accuracy: 0.3367 - val_micro_f1: 0.3341\n","Epoch 98/400\n","66/66 [==============================] - ETA: 0s - loss: 1.8365 - accuracy: 0.2843 - micro_f1: 0.2832\n","Epoch 98: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 22s 336ms/step - loss: 1.8365 - accuracy: 0.2843 - micro_f1: 0.2832 - val_loss: 1.9375 - val_accuracy: 0.2278 - val_micro_f1: 0.2209\n","Epoch 99/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7739 - accuracy: 0.3010 - micro_f1: 0.3007\n","Epoch 99: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 22s 333ms/step - loss: 1.7739 - accuracy: 0.3010 - micro_f1: 0.3007 - val_loss: 1.7755 - val_accuracy: 0.3044 - val_micro_f1: 0.2953\n","Epoch 100/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7675 - accuracy: 0.3110 - micro_f1: 0.3112\n","Epoch 100: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 23s 342ms/step - loss: 1.7675 - accuracy: 0.3110 - micro_f1: 0.3112 - val_loss: 1.7248 - val_accuracy: 0.3000 - val_micro_f1: 0.2909\n","Epoch 101/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7824 - accuracy: 0.2714 - micro_f1: 0.2716\n","Epoch 101: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 24s 369ms/step - loss: 1.7824 - accuracy: 0.2714 - micro_f1: 0.2716 - val_loss: 1.7337 - val_accuracy: 0.2978 - val_micro_f1: 0.2963\n","Epoch 102/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7586 - accuracy: 0.3143 - micro_f1: 0.3142\n","Epoch 102: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 28s 432ms/step - loss: 1.7586 - accuracy: 0.3143 - micro_f1: 0.3142 - val_loss: 1.7200 - val_accuracy: 0.3333 - val_micro_f1: 0.3233\n","Epoch 103/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7653 - accuracy: 0.3076 - micro_f1: 0.3076\n","Epoch 103: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 24s 371ms/step - loss: 1.7653 - accuracy: 0.3076 - micro_f1: 0.3076 - val_loss: 1.7438 - val_accuracy: 0.3333 - val_micro_f1: 0.3308\n","Epoch 104/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7693 - accuracy: 0.3062 - micro_f1: 0.3070\n","Epoch 104: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 21s 314ms/step - loss: 1.7693 - accuracy: 0.3062 - micro_f1: 0.3070 - val_loss: 1.7431 - val_accuracy: 0.3022 - val_micro_f1: 0.3006\n","Epoch 105/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7886 - accuracy: 0.3005 - micro_f1: 0.3005\n","Epoch 105: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 20s 308ms/step - loss: 1.7886 - accuracy: 0.3005 - micro_f1: 0.3005 - val_loss: 1.7103 - val_accuracy: 0.2756 - val_micro_f1: 0.2748\n","Epoch 106/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7916 - accuracy: 0.3057 - micro_f1: 0.3060\n","Epoch 106: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 21s 325ms/step - loss: 1.7916 - accuracy: 0.3057 - micro_f1: 0.3060 - val_loss: 1.7024 - val_accuracy: 0.3767 - val_micro_f1: 0.3728\n","Epoch 107/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7387 - accuracy: 0.3200 - micro_f1: 0.3205\n","Epoch 107: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 20s 311ms/step - loss: 1.7387 - accuracy: 0.3200 - micro_f1: 0.3205 - val_loss: 1.7413 - val_accuracy: 0.2811 - val_micro_f1: 0.2802\n","Epoch 108/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7427 - accuracy: 0.3014 - micro_f1: 0.3020\n","Epoch 108: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 23s 354ms/step - loss: 1.7427 - accuracy: 0.3014 - micro_f1: 0.3020 - val_loss: 1.7168 - val_accuracy: 0.3144 - val_micro_f1: 0.3050\n","Epoch 109/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7808 - accuracy: 0.3124 - micro_f1: 0.3126\n","Epoch 109: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 22s 340ms/step - loss: 1.7808 - accuracy: 0.3124 - micro_f1: 0.3126 - val_loss: 1.8059 - val_accuracy: 0.2900 - val_micro_f1: 0.2812\n","Epoch 110/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7472 - accuracy: 0.3052 - micro_f1: 0.3052\n","Epoch 110: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 24s 357ms/step - loss: 1.7472 - accuracy: 0.3052 - micro_f1: 0.3052 - val_loss: 1.8182 - val_accuracy: 0.3089 - val_micro_f1: 0.2996\n","Epoch 111/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7880 - accuracy: 0.2929 - micro_f1: 0.2935\n","Epoch 111: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 24s 364ms/step - loss: 1.7880 - accuracy: 0.2929 - micro_f1: 0.2935 - val_loss: 1.7171 - val_accuracy: 0.3500 - val_micro_f1: 0.3470\n","Epoch 112/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7620 - accuracy: 0.3195 - micro_f1: 0.3197\n","Epoch 112: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 22s 333ms/step - loss: 1.7620 - accuracy: 0.3195 - micro_f1: 0.3197 - val_loss: 1.7129 - val_accuracy: 0.3500 - val_micro_f1: 0.3470\n","Epoch 113/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7582 - accuracy: 0.3133 - micro_f1: 0.3138\n","Epoch 113: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 22s 336ms/step - loss: 1.7582 - accuracy: 0.3133 - micro_f1: 0.3138 - val_loss: 1.9305 - val_accuracy: 0.2000 - val_micro_f1: 0.1940\n","Epoch 114/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7605 - accuracy: 0.3305 - micro_f1: 0.3297\n","Epoch 114: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 21s 325ms/step - loss: 1.7605 - accuracy: 0.3305 - micro_f1: 0.3297 - val_loss: 1.7174 - val_accuracy: 0.3400 - val_micro_f1: 0.3373\n","Epoch 115/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7363 - accuracy: 0.3195 - micro_f1: 0.3197\n","Epoch 115: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 21s 322ms/step - loss: 1.7363 - accuracy: 0.3195 - micro_f1: 0.3197 - val_loss: 1.6983 - val_accuracy: 0.3411 - val_micro_f1: 0.3308\n","Epoch 116/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7309 - accuracy: 0.3395 - micro_f1: 0.3396\n","Epoch 116: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 23s 342ms/step - loss: 1.7309 - accuracy: 0.3395 - micro_f1: 0.3396 - val_loss: 1.7159 - val_accuracy: 0.3778 - val_micro_f1: 0.3739\n","Epoch 117/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7986 - accuracy: 0.3038 - micro_f1: 0.3041\n","Epoch 117: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 22s 327ms/step - loss: 1.7986 - accuracy: 0.3038 - micro_f1: 0.3041 - val_loss: 1.7355 - val_accuracy: 0.3422 - val_micro_f1: 0.3394\n","Epoch 118/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7421 - accuracy: 0.3181 - micro_f1: 0.3180\n","Epoch 118: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 22s 328ms/step - loss: 1.7421 - accuracy: 0.3181 - micro_f1: 0.3180 - val_loss: 1.6944 - val_accuracy: 0.3144 - val_micro_f1: 0.3125\n","Epoch 119/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7375 - accuracy: 0.3119 - micro_f1: 0.3124\n","Epoch 119: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 22s 329ms/step - loss: 1.7375 - accuracy: 0.3119 - micro_f1: 0.3124 - val_loss: 1.7085 - val_accuracy: 0.3378 - val_micro_f1: 0.3276\n","Epoch 120/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7884 - accuracy: 0.3162 - micro_f1: 0.3178\n","Epoch 120: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 22s 334ms/step - loss: 1.7884 - accuracy: 0.3162 - micro_f1: 0.3178 - val_loss: 1.7431 - val_accuracy: 0.2867 - val_micro_f1: 0.2856\n","Epoch 121/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7453 - accuracy: 0.3110 - micro_f1: 0.3109\n","Epoch 121: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 22s 335ms/step - loss: 1.7453 - accuracy: 0.3110 - micro_f1: 0.3109 - val_loss: 1.6900 - val_accuracy: 0.3689 - val_micro_f1: 0.3653\n","Epoch 122/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7547 - accuracy: 0.3324 - micro_f1: 0.3328\n","Epoch 122: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 22s 332ms/step - loss: 1.7547 - accuracy: 0.3324 - micro_f1: 0.3328 - val_loss: 1.8069 - val_accuracy: 0.2644 - val_micro_f1: 0.2565\n","Epoch 123/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7326 - accuracy: 0.3181 - micro_f1: 0.3174\n","Epoch 123: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 24s 359ms/step - loss: 1.7326 - accuracy: 0.3181 - micro_f1: 0.3174 - val_loss: 1.7590 - val_accuracy: 0.3044 - val_micro_f1: 0.2953\n","Epoch 124/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7315 - accuracy: 0.3295 - micro_f1: 0.3282\n","Epoch 124: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 23s 350ms/step - loss: 1.7315 - accuracy: 0.3295 - micro_f1: 0.3282 - val_loss: 1.6972 - val_accuracy: 0.3344 - val_micro_f1: 0.3394\n","Epoch 125/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7947 - accuracy: 0.2871 - micro_f1: 0.2869\n","Epoch 125: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 25s 377ms/step - loss: 1.7947 - accuracy: 0.2871 - micro_f1: 0.2869 - val_loss: 1.6922 - val_accuracy: 0.2944 - val_micro_f1: 0.2931\n","Epoch 126/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7139 - accuracy: 0.3233 - micro_f1: 0.3229\n","Epoch 126: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 24s 357ms/step - loss: 1.7139 - accuracy: 0.3233 - micro_f1: 0.3229 - val_loss: 1.7030 - val_accuracy: 0.3311 - val_micro_f1: 0.3287\n","Epoch 127/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7442 - accuracy: 0.3129 - micro_f1: 0.3136\n","Epoch 127: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 21s 323ms/step - loss: 1.7442 - accuracy: 0.3129 - micro_f1: 0.3136 - val_loss: 1.6924 - val_accuracy: 0.3433 - val_micro_f1: 0.3405\n","Epoch 128/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7175 - accuracy: 0.3490 - micro_f1: 0.3493\n","Epoch 128: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 22s 335ms/step - loss: 1.7175 - accuracy: 0.3490 - micro_f1: 0.3493 - val_loss: 1.6697 - val_accuracy: 0.3633 - val_micro_f1: 0.3524\n","Epoch 129/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7414 - accuracy: 0.3238 - micro_f1: 0.3234\n","Epoch 129: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 21s 322ms/step - loss: 1.7414 - accuracy: 0.3238 - micro_f1: 0.3234 - val_loss: 1.6829 - val_accuracy: 0.3378 - val_micro_f1: 0.3276\n","Epoch 130/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7361 - accuracy: 0.3105 - micro_f1: 0.3107\n","Epoch 130: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 19s 286ms/step - loss: 1.7361 - accuracy: 0.3105 - micro_f1: 0.3107 - val_loss: 1.7074 - val_accuracy: 0.3122 - val_micro_f1: 0.3179\n","Epoch 131/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7436 - accuracy: 0.3414 - micro_f1: 0.3415\n","Epoch 131: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 23s 355ms/step - loss: 1.7436 - accuracy: 0.3414 - micro_f1: 0.3415 - val_loss: 1.7148 - val_accuracy: 0.3489 - val_micro_f1: 0.3384\n","Epoch 132/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7170 - accuracy: 0.3443 - micro_f1: 0.3432\n","Epoch 132: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 24s 367ms/step - loss: 1.7170 - accuracy: 0.3443 - micro_f1: 0.3432 - val_loss: 1.8295 - val_accuracy: 0.2889 - val_micro_f1: 0.2802\n","Epoch 133/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7426 - accuracy: 0.3419 - micro_f1: 0.3422\n","Epoch 133: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 20s 299ms/step - loss: 1.7426 - accuracy: 0.3419 - micro_f1: 0.3422 - val_loss: 1.7569 - val_accuracy: 0.3244 - val_micro_f1: 0.3147\n","Epoch 134/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7246 - accuracy: 0.3438 - micro_f1: 0.3433\n","Epoch 134: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 20s 304ms/step - loss: 1.7246 - accuracy: 0.3438 - micro_f1: 0.3433 - val_loss: 1.7328 - val_accuracy: 0.3300 - val_micro_f1: 0.3200\n","Epoch 135/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7316 - accuracy: 0.3362 - micro_f1: 0.3366\n","Epoch 135: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 20s 307ms/step - loss: 1.7316 - accuracy: 0.3362 - micro_f1: 0.3366 - val_loss: 1.6992 - val_accuracy: 0.3511 - val_micro_f1: 0.3481\n","Epoch 136/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7515 - accuracy: 0.3233 - micro_f1: 0.3232\n","Epoch 136: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 20s 306ms/step - loss: 1.7515 - accuracy: 0.3233 - micro_f1: 0.3232 - val_loss: 1.7475 - val_accuracy: 0.3244 - val_micro_f1: 0.3147\n","Epoch 137/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7108 - accuracy: 0.3367 - micro_f1: 0.3367\n","Epoch 137: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 19s 294ms/step - loss: 1.7108 - accuracy: 0.3367 - micro_f1: 0.3367 - val_loss: 1.7278 - val_accuracy: 0.3522 - val_micro_f1: 0.3491\n","Epoch 138/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7137 - accuracy: 0.3376 - micro_f1: 0.3371\n","Epoch 138: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 19s 287ms/step - loss: 1.7137 - accuracy: 0.3376 - micro_f1: 0.3371 - val_loss: 1.7095 - val_accuracy: 0.3378 - val_micro_f1: 0.3351\n","Epoch 139/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7127 - accuracy: 0.3529 - micro_f1: 0.3523\n","Epoch 139: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 19s 289ms/step - loss: 1.7127 - accuracy: 0.3529 - micro_f1: 0.3523 - val_loss: 1.7017 - val_accuracy: 0.3056 - val_micro_f1: 0.3039\n","Epoch 140/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7353 - accuracy: 0.3414 - micro_f1: 0.3406\n","Epoch 140: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 20s 300ms/step - loss: 1.7353 - accuracy: 0.3414 - micro_f1: 0.3406 - val_loss: 1.6859 - val_accuracy: 0.3667 - val_micro_f1: 0.3556\n","Epoch 141/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7057 - accuracy: 0.3386 - micro_f1: 0.3384\n","Epoch 141: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 19s 293ms/step - loss: 1.7057 - accuracy: 0.3386 - micro_f1: 0.3384 - val_loss: 1.7286 - val_accuracy: 0.3244 - val_micro_f1: 0.3147\n","Epoch 142/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7406 - accuracy: 0.3114 - micro_f1: 0.3114\n","Epoch 142: val_micro_f1 did not improve from 0.37931\n","66/66 [==============================] - 19s 294ms/step - loss: 1.7406 - accuracy: 0.3114 - micro_f1: 0.3114 - val_loss: 1.7243 - val_accuracy: 0.2700 - val_micro_f1: 0.2619\n","Epoch 143/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7428 - accuracy: 0.3243 - micro_f1: 0.3239\n","Epoch 143: val_micro_f1 improved from 0.37931 to 0.38793, saving model to model_save\\weights-143-0.3239-0.3879.hdf5\n","66/66 [==============================] - 21s 316ms/step - loss: 1.7428 - accuracy: 0.3243 - micro_f1: 0.3239 - val_loss: 1.6865 - val_accuracy: 0.3922 - val_micro_f1: 0.3879\n","Epoch 144/400\n","66/66 [==============================] - ETA: 0s - loss: 1.6943 - accuracy: 0.3238 - micro_f1: 0.3248\n","Epoch 144: val_micro_f1 did not improve from 0.38793\n","66/66 [==============================] - 21s 318ms/step - loss: 1.6943 - accuracy: 0.3238 - micro_f1: 0.3248 - val_loss: 1.6856 - val_accuracy: 0.3233 - val_micro_f1: 0.3136\n","Epoch 145/400\n","66/66 [==============================] - ETA: 0s - loss: 1.6942 - accuracy: 0.3581 - micro_f1: 0.3572\n","Epoch 145: val_micro_f1 did not improve from 0.38793\n","66/66 [==============================] - 20s 301ms/step - loss: 1.6942 - accuracy: 0.3581 - micro_f1: 0.3572 - val_loss: 1.6514 - val_accuracy: 0.3633 - val_micro_f1: 0.3599\n","Epoch 146/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7035 - accuracy: 0.3614 - micro_f1: 0.3619\n","Epoch 146: val_micro_f1 did not improve from 0.38793\n","66/66 [==============================] - 19s 296ms/step - loss: 1.7035 - accuracy: 0.3614 - micro_f1: 0.3619 - val_loss: 1.6785 - val_accuracy: 0.3211 - val_micro_f1: 0.3265\n","Epoch 147/400\n","66/66 [==============================] - ETA: 0s - loss: 1.6895 - accuracy: 0.3510 - micro_f1: 0.3507\n","Epoch 147: val_micro_f1 did not improve from 0.38793\n","66/66 [==============================] - 19s 284ms/step - loss: 1.6895 - accuracy: 0.3510 - micro_f1: 0.3507 - val_loss: 1.6581 - val_accuracy: 0.3456 - val_micro_f1: 0.3427\n","Epoch 148/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7321 - accuracy: 0.3243 - micro_f1: 0.3236\n","Epoch 148: val_micro_f1 did not improve from 0.38793\n","66/66 [==============================] - 20s 303ms/step - loss: 1.7321 - accuracy: 0.3243 - micro_f1: 0.3236 - val_loss: 1.6572 - val_accuracy: 0.3522 - val_micro_f1: 0.3491\n","Epoch 149/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7671 - accuracy: 0.2990 - micro_f1: 0.2991\n","Epoch 149: val_micro_f1 did not improve from 0.38793\n","66/66 [==============================] - 18s 279ms/step - loss: 1.7671 - accuracy: 0.2990 - micro_f1: 0.2991 - val_loss: 1.7343 - val_accuracy: 0.2667 - val_micro_f1: 0.2586\n","Epoch 150/400\n","66/66 [==============================] - ETA: 0s - loss: 1.6767 - accuracy: 0.3662 - micro_f1: 0.3670\n","Epoch 150: val_micro_f1 did not improve from 0.38793\n","66/66 [==============================] - 18s 277ms/step - loss: 1.6767 - accuracy: 0.3662 - micro_f1: 0.3670 - val_loss: 1.6500 - val_accuracy: 0.3767 - val_micro_f1: 0.3728\n","Epoch 151/400\n","66/66 [==============================] - ETA: 0s - loss: 1.6665 - accuracy: 0.3710 - micro_f1: 0.3714\n","Epoch 151: val_micro_f1 improved from 0.38793 to 0.39763, saving model to model_save\\weights-151-0.3714-0.3976.hdf5\n","66/66 [==============================] - 20s 304ms/step - loss: 1.6665 - accuracy: 0.3710 - micro_f1: 0.3714 - val_loss: 1.6592 - val_accuracy: 0.4022 - val_micro_f1: 0.3976\n","Epoch 152/400\n","66/66 [==============================] - ETA: 0s - loss: 1.7026 - accuracy: 0.3400 - micro_f1: 0.3398\n","Epoch 152: val_micro_f1 did not improve from 0.39763\n","66/66 [==============================] - 19s 291ms/step - loss: 1.7026 - accuracy: 0.3400 - micro_f1: 0.3398 - val_loss: 1.7166 - val_accuracy: 0.3200 - val_micro_f1: 0.3179\n","Epoch 153/400\n","66/66 [==============================] - ETA: 0s - loss: 1.6767 - accuracy: 0.3581 - micro_f1: 0.3583\n","Epoch 153: val_micro_f1 did not improve from 0.39763\n","66/66 [==============================] - 19s 290ms/step - loss: 1.6767 - accuracy: 0.3581 - micro_f1: 0.3583 - val_loss: 1.7825 - val_accuracy: 0.3033 - val_micro_f1: 0.2942\n","Epoch 154/400\n","66/66 [==============================] - ETA: 0s - loss: 1.6893 - accuracy: 0.3481 - micro_f1: 0.3481\n","Epoch 154: val_micro_f1 did not improve from 0.39763\n","66/66 [==============================] - 18s 272ms/step - loss: 1.6893 - accuracy: 0.3481 - micro_f1: 0.3481 - val_loss: 1.6763 - val_accuracy: 0.3400 - val_micro_f1: 0.3297\n","Epoch 155/400\n","66/66 [==============================] - ETA: 0s - loss: 1.6731 - accuracy: 0.3662 - micro_f1: 0.3655\n","Epoch 155: val_micro_f1 did not improve from 0.39763\n","66/66 [==============================] - 20s 303ms/step - loss: 1.6731 - accuracy: 0.3662 - micro_f1: 0.3655 - val_loss: 1.6650 - val_accuracy: 0.3567 - val_micro_f1: 0.3459\n","Epoch 156/400\n","66/66 [==============================] - ETA: 0s - loss: 1.6732 - accuracy: 0.3652 - micro_f1: 0.3652\n","Epoch 156: val_micro_f1 did not improve from 0.39763\n","66/66 [==============================] - 20s 301ms/step - loss: 1.6732 - accuracy: 0.3652 - micro_f1: 0.3652 - val_loss: 1.6707 - val_accuracy: 0.3500 - val_micro_f1: 0.3470\n","Epoch 157/400\n","66/66 [==============================] - ETA: 0s - loss: 1.6698 - accuracy: 0.3638 - micro_f1: 0.3646"]}],"source":["tf.keras.backend.clear_session()\n","model.fit(X_train_spectrogram,y_train.astype('int')\\\n","           ,validation_data=(X_test_spectrogram,y_test.astype('int'))\\\n","           ,batch_size=32,epochs=400\\\n","           ,callbacks=[loss_history,checkpoint])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-09-16T14:23:44.480083Z","iopub.status.busy":"2021-09-16T14:23:44.479833Z","iopub.status.idle":"2021-09-16T14:23:44.486448Z","shell.execute_reply":"2021-09-16T14:23:44.485734Z","shell.execute_reply.started":"2021-09-16T14:23:44.480051Z"},"trusted":true},"outputs":[],"source":["opt_res=os.listdir(\"model_save/\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-09-16T14:23:44.488255Z","iopub.status.busy":"2021-09-16T14:23:44.488000Z","iopub.status.idle":"2021-09-16T14:23:44.500468Z","shell.execute_reply":"2021-09-16T14:23:44.499772Z","shell.execute_reply.started":"2021-09-16T14:23:44.488223Z"},"trusted":true},"outputs":[],"source":["result=pd.DataFrame()\n","epoch=[]\n","f1=[]\n","val_f1=[]\n","for i in opt_res:    \n","    epoch.append(i.split('-')[1])\n","    f1.append(i.split('-')[2])\n","    val_f1.append(i.split('-')[3][:6])\n","result['epoch']=epoch\n","result['f1']=f1\n","result['val_f1']=val_f1\n","values=result[result.epoch==str(result.epoch.astype('int').max())]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-09-16T14:23:44.502436Z","iopub.status.busy":"2021-09-16T14:23:44.502140Z","iopub.status.idle":"2021-09-16T14:23:44.511837Z","shell.execute_reply":"2021-09-16T14:23:44.511155Z","shell.execute_reply.started":"2021-09-16T14:23:44.502403Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["We have found optimum result at\n","Epoch:  329 \n","Train F1 score:  0.7163 \n","Test F1 score:  0.7888\n"]}],"source":["print(\"We have found optimum result at\\nEpoch: \",values.iloc[0].epoch,\"\\nTrain F1 score: \",values.iloc[0].f1,\"\\nTest F1 score: \",values.iloc[0].val_f1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.0 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"},"vscode":{"interpreter":{"hash":"525f50cd3df40e9d57f214b2f9bedadf4bf08c85f9f5b3b27734de5b2eace747"}}},"nbformat":4,"nbformat_minor":4}
